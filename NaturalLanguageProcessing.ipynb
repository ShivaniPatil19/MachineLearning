{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Natural', 'Language', 'Toolkit', ',', 'or', 'more', 'commonly', 'NLTK', ',', 'is', 'a', 'suite', 'of', 'libraries', 'and', 'programs', 'for', 'symbolic', 'and', 'statistical', 'natural', 'language', 'processing', '(', 'NLP', ')', 'for', 'English', 'written', 'in', 'the', 'Python', 'programming', 'language', '.', 'It', 'was', 'developed', 'by', 'Steven', 'Bird', 'and', 'Edward', 'Loper', 'in', 'the', 'Department', 'of', 'Computer', 'and', 'Information', 'Science', 'at', 'the', 'University', 'of', 'Pennsylvania', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence= \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\n",
    "tokens= nltk.word_tokenize(sentence)\n",
    "print(tokens)\n",
    "stop_words = stopwords.words('english')\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "tokenized_words = ['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'park']\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words[:5]\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Toolkit', 'NNP'), (',', ','), ('commonly', 'RB'), ('NLTK', 'NNP'), (',', ','), ('suite', 'JJ'), ('libraries', 'NNS'), ('programs', 'NNS'), ('symbolic', 'JJ'), ('statistical', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('English', 'NNP'), ('written', 'VBN'), ('Python', 'NNP'), ('programming', 'VBG'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('developed', 'VBD'), ('Steven', 'NNP'), ('Bird', 'NNP'), ('Edward', 'NNP'), ('Loper', 'NNP'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Information', 'NNP'), ('Science', 'NNP'), ('University', 'NNP'), ('Pennsylvania', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "sentence= \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\n",
    "tokens= nltk.word_tokenize(sentence)\n",
    "\n",
    "wo=[word for word in tokens if word not in stop_words]\n",
    "tagged = nltk.pos_tag(wo ) \n",
    "print(tagged) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Toolkit', 'NNP'), (',', ','), ('commonly', 'RB'), ('NLTK', 'NNP'), (',', ','), ('suite', 'JJ'), ('libraries', 'NNS'), ('programs', 'NNS'), ('symbolic', 'JJ'), ('statistical', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('English', 'NNP'), ('written', 'VBN'), ('Python', 'NNP'), ('programming', 'VBG'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('developed', 'VBD'), ('Steven', 'NNP'), ('Bird', 'NNP'), ('Edward', 'NNP'), ('Loper', 'NNP'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Information', 'NNP'), ('Science', 'NNP'), ('University', 'NNP'), ('Pennsylvania', 'NNP'), ('.', '.')]\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "['the natural language', 'natural language toolkit', 'language toolkit or', 'toolkit or more', 'or more commonly', 'more commonly nltk', 'commonly nltk is', 'nltk is a', 'is a suite', 'a suite of', 'suite of libraries', 'of libraries and', 'libraries and programs', 'and programs for', 'programs for symbolic', 'for symbolic and', 'symbolic and statistical', 'and statistical natural', 'statistical natural language', 'natural language processing', 'language processing nlp', 'processing nlp for', 'nlp for english', 'for english written', 'english written in', 'written in the', 'in the python', 'the python programming', 'python programming language', 'programming language it', 'language it was', 'it was developed', 'was developed by', 'developed by steven', 'by steven bird', 'steven bird and', 'bird and edward', 'and edward loper', 'edward loper in', 'loper in the', 'in the department', 'the department of', 'department of computer', 'of computer and', 'computer and information', 'and information science', 'information science at', 'science at the', 'at the university', 'the university of', 'university of pennsylvania']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop_words = stopwords.words('english')\n",
    "sentence= \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\"\n",
    "tokens= nltk.word_tokenize(sentence)\n",
    "\n",
    "wo=[word for word in tokens if word not in stop_words]\n",
    "tagged = nltk.pos_tag(wo ) \n",
    "print(tagged) \n",
    "print(\"\\n \\n \\n\")\n",
    "sentence=sentence.lower()\n",
    "sentence = re.sub(r'[^a-zA-Z0-9\\s]', ' ', sentence)\n",
    "tokens = [tokens for tokens in sentence.split(\" \") if tokens != \"\"]\n",
    "ngrams = zip(*[tokens[i:] for i in range(3)])\n",
    "ou=[\" \".join(ngram) for ngram in ngrams]\n",
    "print(ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello this is a', 'this is a lab', 'is a lab assingment']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "sentence=sentence.lower()\n",
    "sentence=\"hello this is a lab assingment\"\n",
    "sentence = re.sub(r'[^a-zA-Z0-9\\s]', ' ', sentence)\n",
    "tokens = [tokens for tokens in sentence.split(\" \") if tokens != \"\"]\n",
    "ngrams = zip(*[tokens[i:] for i in range(4)])\n",
    "ou=[\" \".join(ngram) for ngram in ngrams]\n",
    "print(ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dern', 'desi', 'dheri', 'dier', 'dine', 'diner', 'dire', 'disfen', 'dish', 'disher', 'drip', 'eshin', 'feis', 'fend', 'fern', 'fide', 'fiend', 'fiendish', 'fiendship', 'find', 'finder', 'fine', 'fineish', 'finer', 'finis', 'finish', 'finished', 'finisher', 'fire', 'fired', 'firn', 'fise', 'fish', 'fished', 'fisher', 'fresh', 'fried', 'friend', 'friendship', 'heii', 'heir', 'hend', 'herd', 'hern', 'hers', 'hide', 'hider', 'hind', 'hinder', 'hipe', 'hiper', 'hire', 'hired', 'hirse', 'hisn', 'hispid', 'ides', 'inde', 'indri', 'infer', 'inship', 'inside', 'insider', 'inspire', 'inspired', 'ipid', 'irid', 'irides', 'iris', 'irised', 'neif', 'nesh', 'nide', 'nidi', 'nife', 'nisei', 'pend', 'penis', 'peri', 'perish', 'pern', 'pied', 'pien', 'piend', 'pier', 'pierid', 'pifine', 'pind', 'pinder', 'pine', 'pined', 'piner', 'pinfish', 'pirn', 'pirnie', 'pise', 'pish', 'prefinish', 'pride', 'pried', 'prine', 'redfin', 'redfish', 'redip', 'refind', 'refinish', 'reif', 'rein', 'reins', 'reis', 'rend', 'renish', 'repin', 'reps', 'resh', 'reship', 'resin', 'resp', 'respin', 'rhein', 'rhine', 'ride', 'riden', 'rife', 'rind', 'rine', 'rinse', 'ripe', 'ripen', 'rise', 'risen', 'rishi', 'risp', 'send', 'serf', 'serif', 'serin', 'serphid', 'shed', 'shend', 'sher', 'sherif', 'sherifi', 'shide', 'shied', 'shier', 'shin', 'shine', 'shiner', 'ship', 'shire', 'shred', 'shrend', 'shrine', 'shrip', 'side', 'sider', 'siderin', 'sidhe', 'sidi', 'sier', 'sife', 'sind', 'sinder', 'sine', 'sinh', 'sipe', 'siper', 'sipid', 'sire', 'siren', 'sirih', 'sned', 'snerp', 'snide', 'snip', 'snipe', 'sniper', 'sped', 'spend', 'spider', 'spied', 'spier', 'spin', 'spinder', 'spine', 'spined', 'spire', 'spired', 'spried', 'fire', 'fish', 'friend', 'send', 'ship', 'side']\n",
      "\n",
      "\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "puzzle_letters = nltk.FreqDist('friendship')\n",
    "wordlist = nltk.corpus.words.words()\n",
    "\n",
    "c=[w for w in wordlist if len(w) >= 4  and nltk.FreqDist(w) <= puzzle_letters] \n",
    "print(c)\n",
    "print(\"\\n\")\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
